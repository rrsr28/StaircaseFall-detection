{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f66cf2f-e0e5-4da6-9b68-32332d4a289e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Fall Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa44e941-f7a1-4ee9-b67a-305b7cf70a94",
   "metadata": {},
   "source": [
    "###### Staircase, Ladder, Escalator, Steps, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7351fc90-e614-4189-95ce-f4ddc4e5e65b",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cd0367-ef93-4df3-8245-b004c6910aec",
   "metadata": {},
   "source": [
    "I have a 2 main files :\n",
    "- main.py   ->  Detects falls in the Video (using YOLOv7)\n",
    "- main2.py  ->  Detects if the fall was specifically from stairs (using OWL-ViT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3a076c-61eb-417d-b9de-f76602739b49",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f8a851-280f-4bda-b666-c21dbe4cccc7",
   "metadata": {},
   "source": [
    "### Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d57ffa8-f44b-4f27-a192-948c394821d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fall_detection(poses, image):\n",
    "    global falls_boxs\n",
    "    is_fall = False\n",
    "    bbox = None\n",
    "\n",
    "    for pose in poses:\n",
    "        xmin, ymin = (pose[2] - pose[4] / 2), (pose[3] - pose[5] / 2)\n",
    "        xmax, ymax = (pose[2] + pose[4] / 2), (pose[3] + pose[5] / 2)\n",
    "\n",
    "        left_shoulder_y = pose[23]\n",
    "        left_shoulder_x = pose[22]\n",
    "        right_shoulder_y = pose[26]\n",
    "        left_body_y = pose[41]\n",
    "        left_body_x = pose[40]\n",
    "        right_body_y = pose[44]\n",
    "\n",
    "        len_factor = math.sqrt(((left_shoulder_y - left_body_y) ** 2 + (left_shoulder_x - left_body_x) ** 2))\n",
    "        left_foot_y = pose[53]\n",
    "        right_foot_y = pose[56]\n",
    "        dx = int(xmax) - int(xmin)\n",
    "        dy = int(ymax) - int(ymin)\n",
    "        difference = dy - dx\n",
    "\n",
    "        if left_shoulder_y > left_foot_y - len_factor and left_body_y > left_foot_y - (len_factor / 2) and left_shoulder_y > left_body_y - (len_factor / 2) or (right_shoulder_y > right_foot_y - len_factor and right_body_y > right_foot_y - (len_factor / 2) and right_shoulder_y > right_body_y - (len_factor / 2)) or difference < 0:\n",
    "            is_fall = True\n",
    "            bbox = (xmin, ymin, xmax, ymax)\n",
    "            falls_boxs.append((xmin, ymin, xmax, ymax))\n",
    "            break\n",
    "\n",
    "    return is_fall, bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caced6e-dafa-4dad-968a-5f9e9b6f5ff6",
   "metadata": {},
   "source": [
    "The function then checks various conditions to determine if a fall has occurred. These conditions are based on the relative positions of key points, such as shoulders, hips, and feet. Specifically:\n",
    "- It calculates the length factor, which is the distance between the left shoulder and left hip. This is used as a reference length for detecting falls.\n",
    "- It checks if the left shoulder is below the left foot by at least the length factor, indicating a potential fall.\n",
    "- It checks if the left hip is below the left foot by at least half the length factor, further confirming the fall.\n",
    "- It checks if the difference between the width and height of the bounding box is negative, which may indicate a sudden change in posture, also        suggesting a fall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbff69f-053e-49fe-8234-c5dee0a5bd06",
   "metadata": {},
   "source": [
    "If any of the conditions for a fall are met, the function sets the is_fall flag to True and records the bounding box (bbox) of the detected fall. The bounding box coordinates are appended to the global list falls_boxs, which presumably stores bounding boxes of all detected falls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253b6aec-d0ed-4d92-9bad-d5d2a8fb85fa",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802ddb10-046d-424a-9656-a3ca035af420",
   "metadata": {},
   "source": [
    "#### Zero Shot Object Detection\n",
    "\n",
    "This code continuously reads frames from a video stream. For each frame, it applies object detection using OwlViT to identify objects like stairs, ladders, escalators, and steps. After detecting these objects, it checks if any of them intersect with previously detected bounding boxes, which are stored in a CSV file and represent falls. If an intersection is found, it prints a message indicating that a fall has been detected from the object. (example : Fall from Ladder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a941f2-0f53-4c43-a783-099247859e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Object detection with OwlViT\n",
    "    image_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    texts = [[\"stairs\", \"ladder\", \"escalator\", \"steps\"]]\n",
    "    inputs = processor(text=texts, images=image_pil, return_tensors=\"pt\")\n",
    "    outputs = model_vit(**inputs)\n",
    "    target_sizes = torch.Tensor([image_pil.size[::-1]])\n",
    "    results = processor.post_process_object_detection(outputs=outputs, target_sizes=target_sizes, threshold=0.1)\n",
    "    text = texts[0]\n",
    "    boxes, scores, labels = results[0][\"boxes\"], results[0][\"scores\"], results[0][\"labels\"]\n",
    "\n",
    "    # Draw rectangles for OwlViT object detection\n",
    "    for box, score, label in zip(boxes, scores, labels):\n",
    "        box = [int(i) for i in box.tolist()]\n",
    "        print(box)\n",
    "        intersection = check_intersection_with_csv(csv_file, box)\n",
    "        print(intersection)\n",
    "        print(f\"Detected {text[label]} with confidence {round(score.item(), 3)} at location {box}\")\n",
    "        cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"{text[label]}: {score:.2f}\", (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                    (0, 255, 0), 2)\n",
    "\n",
    "        # Check if intersection is detected and print the message\n",
    "        if intersection:\n",
    "            print(f\"Fall detected from {text[label]}\")\n",
    "            cv2.putText(frame, f\"Fall detected from {text[label]}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Show frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166ccf8f-a6a9-4f71-8b71-9519ea833490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_intersection_with_csv(csv_file, box2):\n",
    "    box1 = read_boxes_from_csv(csv_file)\n",
    "    xmin2, ymin2, xmax2, ymax2 = box2\n",
    "\n",
    "    for box in box1:\n",
    "        xmin1, ymin1, xmax1, ymax1 = box\n",
    "        # Check if boxes intersect along the x-axis\n",
    "        x_intersect = (xmin1 <= xmax2) and (xmax1 >= xmin2)\n",
    "        # Check if boxes intersect along the y-axis\n",
    "        y_intersect = (ymin1 <= ymax2) and (ymax1 >= ymin2)\n",
    "        # If both x and y intersections occur, the boxes intersect or touch\n",
    "        if x_intersect and y_intersect:\n",
    "            return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bef67a4-38d0-4f51-8fe0-22a1f86d9223",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c755b653-945f-45e0-9d49-ae527e1896fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
